{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "131rzidc_ufi0rh5NavdL8XeseB5I4EJI",
      "authorship_tag": "ABX9TyNySfhp3DhMoH2lIK9ogVvI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maralthesage/visualizing_cnns/blob/main/Thesis_Visualization_Codes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualizing CNNs\n",
        "\n",
        "In this Notebook, two different methods of visualization are used to explain the model's prediction in CNN architectures VGG16, MobileNet and Inception V3, namely Grad-CAM and Occlusion Analysis. The codes for these two methods are adapted from the following resources:\n",
        "\n",
        "* For Grad-CAM : https://keras.io/examples/vision/grad_cam/\n",
        "* For Occlusion Analysis : https://deel-ai.github.io/xplique/api/attributions/occlusion/\n",
        "\n",
        "First thing, we need to install the Xplique library for Occlusion Visualization and then importing the required libraries."
      ],
      "metadata": {
        "id": "r7wkzT_GR3rA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UOq-TljsR1mO"
      },
      "outputs": [],
      "source": [
        "!pip install -U -q xplique"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "from IPython.display import Image, display\n",
        "\n",
        "## --- Xplique tools --- ##\n",
        "import xplique\n",
        "from xplique.attributions import Occlusion\n",
        "from xplique.plots import plot_attributions\n",
        "\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "yGT9Ib1QSgaA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the block below, choose the proper model name (from the given list) to visualize the results with respect to that certain model and mode of training it was trained on."
      ],
      "metadata": {
        "id": "7sFcgwpZx_UY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## choose the name of models from the following list ==> \n",
        "## ['VGG-FT', 'VGG-FX', 'VGG-TR', 'MN-FT', 'MN-FX', 'MN-TR', 'IN-FT', 'IN-FX', 'IN-TR']\n",
        "model_name = 'VGG-FT'\n",
        "## models' paths are relative and the following address needs to be changed.\n",
        "models_path = '/content/drive/MyDrive/Colab Notebooks/SomeFolder/'"
      ],
      "metadata": {
        "id": "8Ltcfjmyx4vs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Import\n",
        "\n",
        "At this section, the saved models are being imported from where you have them. This was originally addressed to Google Drive.\n",
        "\n",
        "The following code block also sets the further setting required for the visualizations to work. \n",
        "\n",
        "**Please do NOT change anything in the following code**, but run it for the rest of the notebook to work properly. \n"
      ],
      "metadata": {
        "id": "lEOXc6D2SyUA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### ------------------- Do Not Change This Code ------------------- ###\n",
        "model = tf.keras.models.load_model(models_path+model_name)\n",
        "\n",
        "if 'VGG' in model_name:\n",
        "  IMG_SIZE = 224\n",
        "  last_conv_layer = 'block5_conv3' \n",
        "  preprocess_input = tf.keras.applications.vgg16.preprocess_input\n",
        "\n",
        "elif 'MN' in model_name:\n",
        "  IMG_SIZE = 224\n",
        "  last_conv_layer = 'conv_pw_13' \n",
        "  preprocess_input = tf.keras.applications.mobilenet.preprocess_input\n",
        "  \n",
        "elif 'IN' in model_name:\n",
        "  IMG_SIZE = 299\n",
        "  preprocess_input = tf.keras.applications.inception_v3.preprocess_input\n",
        "  if 'FX' in model_name:\n",
        "    last_conv_layer = 'conv2d_93' \n",
        "  elif 'FT' in model_name:\n",
        "    last_conv_layer = 'conv2d_281' \n",
        "  elif 'TR' in model_name:\n",
        "    last_conv_layer = 'conv2d_375' \n",
        "\n"
      ],
      "metadata": {
        "id": "gnbFmtk9SvVI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading Images \n",
        "\n",
        "Here you need to change the `file_paths` to a path relative to where you keep the test data."
      ],
      "metadata": {
        "id": "mTnCV6kojiVn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## this path is relative to where you download and save the test_dataset file i shared as comment on top of this notebook\n",
        "file_paths = '/content/drive/MyDrive/SomeFolder/data/'\n",
        "\n",
        "img_paths = [\n",
        " f'{file_paths}Strawberry___healthy/15b5d300-a3f7-4e46-9f33-47f99c5d8364___RS_HL 4832.JPG',\n",
        " f'{file_paths}Strawberry___Leaf_scorch/d306834f-2362-49bc-aadb-8da5364d88f1___RS_L.Scorch 1334.JPG',\n",
        " f'{file_paths}Tomato___Leaf_Mold/528ee5e6-6c7f-4676-9fe2-fe3956a73b00___Crnl_L.Mold 6739.JPG',\n",
        " f'{file_paths}Peach___Bacterial_spot/316b51d9-ffb1-4ccd-ad84-62fe1d1d3e4d___Rut._Bact.S 1042.JPG',\n",
        " f'{file_paths}Apple___Cedar_apple_rust/f90bff66-b339-4a6f-acf4-85ed13aebff8___FREC_C.Rust 9843-horizontalflip.JPG',\n",
        " f'{file_paths}Tomato___Tomato_Yellow_Leaf_Curl_Virus/36f918e5-8c49-4820-a2fe-f3355e9f95e4___YLCV_NREC 2537.JPG',\n",
        " f'{file_paths}Potato___healthy/b925ad3e-fc49-497d-a6eb-115f0de20800___RS_HL 4170.JPG',\n",
        " f'{file_paths}Potato___Late_blight/d994fd7e-a338-42c5-ac37-ede01c18999e___RS_LB 5134.JPG',\n",
        " f'{file_paths}Tomato___healthy/4ed0a372-fe3d-49a6-82a1-2e904e6c66e3___GH_HL Leaf 200-horizontalflip.JPG',\n",
        " f'{file_paths}Corn_(maize)___Northern_Leaf_Blight/ccb8b8c4-840f-44b4-9a6e-43109f828b8c___RS_NLB 4091.JPG',\n",
        " f'{file_paths}Tomato___Target_Spot/e6c089fa-5b16-46e6-a8d9-f742377b43a8___Com.G_TgS_FL 8352.JPG',\n",
        " f'{file_paths}Apple___Apple_scab/fa9c1112-27fc-42db-930d-7e4956267ab5___FREC_Scab 3174.JPG', \n",
        " f'{file_paths}Soybean___healthy/073d9dd0-012e-468d-96b9-494cb684d802___RS_HL 3563.JPG',\n",
        " f'{file_paths}Grape___Leaf_blight_(Isariopsis_Leaf_Spot)/e93f37ed-7dfd-401f-a470-0f932fecdd75___FAM_L.Blight 3637.JPG',\n",
        " f'{file_paths}Orange___Haunglongbing_(Citrus_greening)/08b7e039-7264-4a3d-b7d6-6e13c5bbac56___CREC_HLB 7417.JPG',\n",
        " f'{file_paths}Squash___Powdery_mildew/67c186ab-1874-4500-ae6b-9a575c8dcb42___MD_Powd.M 0752.JPG',\n",
        " f'{file_paths}Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot/d1f96a7c-c108-45a4-82f6-ffe84b0d081f___RS_GLSp 9304.JPG',\n",
        " f'{file_paths}Cherry_(including_sour)___Powdery_mildew/84ff1c46-5c01-4136-bef5-59cd2d0ed812___FREC_Pwd.M 0572.JPG',\n",
        " f'{file_paths}Corn_(maize)___Common_rust_/RS_Rust 1869.JPG',\n",
        " f'{file_paths}Pepper,_bell___Bacterial_spot/e05d9bf6-8d96-4fb5-8ea4-b9bab9e9bb8f___JR_B.Spot 3142.JPG',\n",
        " f'{file_paths}Pepper,_bell___healthy/2d117ef0-5705-4814-b191-1d184204452f___JR_HL 7744.JPG',\n",
        " f'{file_paths}Tomato___Late_blight/121097dd-b0cb-436b-9b2f-7dab30c86872___GHLB_PS Leaf 37.1 Day 13.jpg']"
      ],
      "metadata": {
        "id": "M9WzIXhVchvw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Class Names\n",
        "\n",
        "For printing purposes of the predictions and labels. "
      ],
      "metadata": {
        "id": "RDxbdG73c9pz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = ['Apple___Apple_scab',\n",
        " 'Apple___Black_rot',\n",
        " 'Apple___Cedar_apple_rust',\n",
        " 'Apple___healthy',\n",
        " 'Blueberry___healthy',\n",
        " 'Cherry_(including_sour)___Powdery_mildew',\n",
        " 'Cherry_(including_sour)___healthy',\n",
        " 'Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot',\n",
        " 'Corn_(maize)___Common_rust_',\n",
        " 'Corn_(maize)___Northern_Leaf_Blight',\n",
        " 'Corn_(maize)___healthy',\n",
        " 'Grape___Black_rot',\n",
        " 'Grape___Esca_(Black_Measles)',\n",
        " 'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)',\n",
        " 'Grape___healthy',\n",
        " 'Orange___Haunglongbing_(Citrus_greening)',\n",
        " 'Peach___Bacterial_spot',\n",
        " 'Peach___healthy',\n",
        " 'Pepper,_bell___Bacterial_spot',\n",
        " 'Pepper,_bell___healthy',\n",
        " 'Potato___Early_blight',\n",
        " 'Potato___Late_blight',\n",
        " 'Potato___healthy',\n",
        " 'Raspberry___healthy',\n",
        " 'Soybean___healthy',\n",
        " 'Squash___Powdery_mildew',\n",
        " 'Strawberry___Leaf_scorch',\n",
        " 'Strawberry___healthy',\n",
        " 'Tomato___Bacterial_spot',\n",
        " 'Tomato___Early_blight',\n",
        " 'Tomato___Late_blight',\n",
        " 'Tomato___Leaf_Mold',\n",
        " 'Tomato___Septoria_leaf_spot',\n",
        " 'Tomato___Spider_mites Two-spotted_spider_mite',\n",
        " 'Tomato___Target_Spot',\n",
        " 'Tomato___Tomato_Yellow_Leaf_Curl_Virus',\n",
        " 'Tomato___Tomato_mosaic_virus',\n",
        " 'Tomato___healthy']"
      ],
      "metadata": {
        "id": "5T6SKsqactcu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Functions for preparing Images and Labels\n",
        "\n",
        "The `get_img_array` function is adopted from Grad-CAM resource in https://keras.com. The rest are for name cleaning purposes. Just running the following would be enough."
      ],
      "metadata": {
        "id": "KOLpIN9HczQ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def get_img_array(img_path, size):\n",
        "    # `img` is a PIL image of size 299x299\n",
        "    img = tf.keras.preprocessing.image.load_img(img_path, target_size=size)\n",
        "    # `array` is a float32 Numpy array of shape (299, 299, 3)\n",
        "    array = tf.keras.preprocessing.image.img_to_array(img)\n",
        "    # We add a dimension to transform our array into a \"batch\"\n",
        "    array = np.expand_dims(array, axis=0)\n",
        "    return array\n",
        "\n",
        "## ---------------------------------------------- ##\n",
        "## Clean up the class name for visualization use\n",
        "\n",
        "def clean_name(filename):\n",
        "  splitted_f = filename.split('_')\n",
        "  name_pred = \" \".join(word for word in splitted_f if word)\n",
        "  return name_pred\n",
        "\n",
        "## ---------------------------------------------- ##\n",
        "## Get image predicted class name from the model\n",
        "\n",
        "def class_pred(filepath):\n",
        "  img = preprocess_input(get_img_array(filepath, size=IMG_SIZE))\n",
        "  # img = get_img_array(filepath,(224,224))\n",
        "  preds = model.predict(img,verbose=0)\n",
        "  name_pred = class_names[np.argmax(preds)]\n",
        "  # name_pred = clean_name(name_pred)\n",
        "  return name_pred\n",
        "\n",
        "## ---------------------------------------------- ##\n",
        "## Get image true label from the filename\n",
        "\n",
        "def true_label(filepath):\n",
        "  for name in class_names:\n",
        "    if name in filepath:\n",
        "      return name\n",
        "\n"
      ],
      "metadata": {
        "id": "fl4SE-pCcy20"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Occlusion Analysis\n",
        "\n",
        "The following two blocks will visualize the above added images using Occlusion method. The second one may take a while on a CPU."
      ],
      "metadata": {
        "id": "rQCJIthsdHyD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def occlusion(img_path):\n",
        "\n",
        "    x =  np.expand_dims(tf.keras.preprocessing.image.load_img(img_path, target_size=(IMG_SIZE,IMG_SIZE)),0)\n",
        "    x =  np.array(x, dtype=np.float32) / 255.0\n",
        "\n",
        "    \n",
        "    y =  np.expand_dims(tf.keras.utils.to_categorical(class_names.index(true_label(img_path)), 38), 0)\n",
        "\n",
        "    explainer = Occlusion(model, \n",
        "                          patch_size=(32, 32), patch_stride=(16, 16), \n",
        "                          batch_size=16, occlusion_value=0)\n",
        "\n",
        "    # compute explanation by calling the explainer\n",
        "    explanation = explainer.explain(x, y)\n",
        "    plot_attributions(explanation, x, img_size=3.2, cmap='jet', cols=1, alpha=.7)\n"
      ],
      "metadata": {
        "id": "jRe9TPB6dNrg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for id, img_path in enumerate(img_paths):\n",
        "    occlusion(img_path)"
      ],
      "metadata": {
        "id": "pz2yZYlveG3o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Grad-CAM \n",
        "\n",
        "The following code blocks will visualize models through Grad-CAM. The code does not require any modification and running it given all the data is loaded properly should visualize the results.\n"
      ],
      "metadata": {
        "id": "F2yQ1O6NebCy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
        "    grad_model = tf.keras.models.Model(\n",
        "        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
        "    )\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        last_conv_layer_output, preds = grad_model(img_array)\n",
        "        if pred_index is None:\n",
        "            pred_index = tf.argmax(preds[0])\n",
        "        class_channel = preds[:, pred_index]\n",
        "\n",
        "\n",
        "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
        "\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "\n",
        "    last_conv_layer_output = last_conv_layer_output[0]\n",
        "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
        "    heatmap = tf.squeeze(heatmap)\n",
        "\n",
        "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
        "    return heatmap.numpy()"
      ],
      "metadata": {
        "id": "OIi5gDtsea1O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_heatmaps(image_path=img_path, model=model):\n",
        "  model.layers[-1].activation = None\n",
        "\n",
        "  img_array = preprocess_input(get_img_array(img_path, size=(IMG_SIZE,IMG_SIZE)))\n",
        "\n",
        "  heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer)\n",
        "\n",
        "  return heatmap"
      ],
      "metadata": {
        "id": "uyJZer3LferI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_and_display_gradcam(img_path, cam_path=\"cam.jpg\", alpha=1,id=0):\n",
        "    # Load the original image\n",
        "    img = keras.preprocessing.image.load_img(img_path)\n",
        "    img = keras.preprocessing.image.img_to_array(img)\n",
        "\n",
        "    # Rescale heatmap to a range 0-255\n",
        "    heatmap = create_heatmaps(img_path, model=model)\n",
        "    heatmap = np.uint8(255 * heatmap)\n",
        "\n",
        "    # Use jet colormap to colorize heatmap\n",
        "    jet = cm.get_cmap(\"jet\")\n",
        "\n",
        "    # Use RGB values of the colormap\n",
        "    jet_colors = jet(np.arange(256))[:, :3]\n",
        "    jet_heatmap = jet_colors[heatmap]\n",
        "\n",
        "    # Create an image with RGB colorized heatmap\n",
        "    jet_heatmap = keras.preprocessing.image.array_to_img(jet_heatmap)\n",
        "    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n",
        "    jet_heatmap = keras.preprocessing.image.img_to_array(jet_heatmap)\n",
        "\n",
        "    # Superimpose the heatmap on original image\n",
        "    superimposed_img = jet_heatmap * alpha + img\n",
        "    superimposed_img = keras.preprocessing.image.array_to_img(superimposed_img)\n",
        "\n",
        "    plt.imshow(superimposed_img)\n",
        "    plt.axis('off')\n",
        "    plt.show();\n"
      ],
      "metadata": {
        "id": "Mmvrl5x0gsOt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating heatmaps and visualizing Grad-CAM\n",
        "\n",
        "The following code will print the true_label and predicted label as well as the softmax prediction of the model along with the Grad-CAM visualization. \n",
        "\n",
        "Note: Sometimes the `Pred Value` print as a large number and that is a bug that occur after running the heatmap code. In case that happens, only reloading the saved model from the top of this notebook will fix the problem."
      ],
      "metadata": {
        "id": "z-S58m_eVve4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for id,img_path in enumerate(img_paths):\n",
        "  image = preprocess_input(get_img_array(img_path, size=(IMG_SIZE,IMG_SIZE)))\n",
        "  pred  = model.predict(image,verbose=0)\n",
        "  heatmap = create_heatmaps(img_path,model)\n",
        "\n",
        "  print(f\"True Label: {true_label(img_path)}\")\n",
        "  print(f\"Prediction: {class_names[pred.argmax()]}\")\n",
        "  print(f\"Pred Value: {pred.max():.2%}\")\n",
        "  save_and_display_gradcam(img_path,id=id)"
      ],
      "metadata": {
        "id": "Wl0dY2jLgogV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}