{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maralthesage/visualizing_cnns/blob/main/Thesis_Model_Pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DnA4R2SuDFRS"
      },
      "source": [
        "# Model Pipeline\n",
        "\n",
        "In this notebook we train VGG16 - MobileNet - Inception V3 in 3 modes of:\n",
        "1. Training from scratch\n",
        "2. Used as a feature extractor with pretrained weights of the `imagenet` with a dense layer classifier on top\n",
        "3. Fine-tuned with the weights of `imagenet` with a lr = 1e-5.\n",
        "\n",
        "All three modes are done using a balanced subset of PlantVillage Dataset and is done for 40 epochs.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tW5KHMQ0D0uK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
        "from tensorflow.keras import Model\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import seaborn as sns\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJY7kdRNbaSD"
      },
      "source": [
        "# Model Configurations\n",
        "\n",
        "To train a model from (VGG16, MobileNet or Inception V3) please specify the `model_name` in the following way:\n",
        "\n",
        "* VGG for VGG16\n",
        "* MN for MobileNet\n",
        "* IN for Inception V3\n",
        "\n",
        "The `mode` will be important in the next phase where you need to choose the setting for training and the choices are:\n",
        "\n",
        "* TR for training from scratch\n",
        "* FX for feature extraction\n",
        "* FT for Fine-tuning\n",
        "\n",
        "These parameters determine the name of the saved models, which won't be required here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "lJqERbMqQusg"
      },
      "outputs": [],
      "source": [
        "## choose the name of models from the following list ==> \n",
        "## ['VGG-FT-40','VGG-FX-40','VGG-TR-40', 'MN-FT-40','MN-FX-40','MN-TR-40', 'IN-FT-40','IN-FX-40','IN-TR-40']\n",
        "path = '/content/drive/MyDrive/Colab Notebooks'\n",
        "mode = 'TR'\n",
        "model_name = 'MN'\n",
        "\n",
        "## models' paths are relative and the following address needs to be changed.\n",
        "models_path = f'{path}/{model_name}-{mode}'\n",
        "\n",
        "model = tf.keras.models.load_model(models_path)\n",
        "\n",
        "if 'VGG' in model_name:\n",
        "  IMG_SIZE = 224\n",
        "  preprocess_input = tf.keras.applications.vgg16.preprocess_input\n",
        "\n",
        "elif 'MN' in model_name:\n",
        "  IMG_SIZE = 224\n",
        "  preprocess_input = tf.keras.applications.mobilenet.preprocess_input\n",
        "  \n",
        "elif 'IN' in model_name:\n",
        "  IMG_SIZE = 299\n",
        "  preprocess_input = tf.keras.applications.inception_v3.preprocess_input\n",
        "\n",
        "\n",
        "# model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting up Datasets\n",
        "\n",
        "Below we use `ImageDataGenerator` method from keras to create our dataset as well as preprocess them in one step. `IMG_SIZE` come from the above block where we chose the model."
      ],
      "metadata": {
        "id": "Sh0PIUavrq8E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EBuvLoBgBZRO"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 32\n",
        "\n",
        "data_dir = \"/content/drive/MyDrive/output/\"\n",
        "\n",
        "\n",
        "train_dataset = ImageDataGenerator(preprocessing_function=preprocess_input, zoom_range=0.2, rotation_range=20)\n",
        "\n",
        "validation_dataset = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "test_dataset = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "\n",
        "\n",
        "# train_dataset = train_dataset.flow_from_directory(\n",
        "#         data_dir+'train',\n",
        "#         target_size= (IMG_SIZE, IMG_SIZE),\n",
        "#         class_mode=\"categorical\",\n",
        "#         seed = 42,\n",
        "#         batch_size=BATCH_SIZE,\n",
        "#         shuffle=True)\n",
        "\n",
        "# validation_dataset = validation_dataset.flow_from_directory(\n",
        "#         data_dir+'valid',\n",
        "#         target_size= (IMG_SIZE, IMG_SIZE),\n",
        "#         class_mode=\"categorical\",\n",
        "#         seed = 42,\n",
        "#         batch_size=BATCH_SIZE,\n",
        "#         shuffle=True)\n",
        "\n",
        "test_dataset = test_dataset.flow_from_directory(\n",
        "        data_dir+'test',\n",
        "        target_size= (IMG_SIZE, IMG_SIZE),\n",
        "        class_mode=\"categorical\",\n",
        "        seed = 42,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pt5C4T0MbwlM"
      },
      "source": [
        "## Creating the base model \n",
        "\n",
        "There are three sub blocks in the following code block, each are for TR, FX, and FT modes of training in that order. they are separated by two horizontal lines. \n",
        "\n",
        "* In case you want to train a model from scratch, keep the first subblock uncommented and the other two commented (as it is here).\n",
        "\n",
        "* In case you want to use the base_model as a feature extractor, commented out the 1 and 3 subblocks and uncomment the 2nd subblock\n",
        "\n",
        "* In case you want the base_model to be fine-tuned, comment out the 1st and 2nd subblocks and uncomment the third subblock."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8MVettN0EAzq"
      },
      "outputs": [],
      "source": [
        "## Run the following Code for TR mode (Training from Scratch)\n",
        "base_model = tf.keras.applications.vgg16.VGG16(weights = None ,include_top = False, input_shape= (IMG_SIZE, IMG_SIZE, 3))\n",
        "base_model.trainable = True\n",
        "\n",
        "### ------------------------------------------------- ###\n",
        "# ## Run the following Code for FX mode (Feature Extraction)\n",
        "\n",
        "# base_model = tf.keras.applications.vgg16.VGG16(weights = 'imagenet' ,include_top = False, input_shape= (IMG_SIZE, IMG_SIZE, 3))\n",
        "# base_model.trainable = False\n",
        "\n",
        "### ------------------------------------------------- ###\n",
        "# ## Run the following Code for FT mode (Fine Tuning)\n",
        "\n",
        "# base_model = tf.keras.applications.vgg16.VGG16(weights = 'imagenet' ,include_top = False, input_shape= (IMG_SIZE, IMG_SIZE, 3))\n",
        "# base_model.trainable = True"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, you only need to uncomment one of the `opt` which stands for optimizers based on the training mode you are working in. in case of FT mode, uncomment the first `opt` and for TR and FT modes, uncomment the 2nd `opt` so that the learning rate is adjusted. \n",
        "\n",
        "You can see the `model.summary()` by uncommenting it."
      ],
      "metadata": {
        "id": "OUFuBYyrt71H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3jFMAXp9b0JM"
      },
      "outputs": [],
      "source": [
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "out = Dense(38, activation='softmax')(x)\n",
        "model = Model(inputs=base_model.input, outputs=out)\n",
        "\n",
        "### ------------------------------------------------- ###\n",
        "## Uncomment this in case you are in FT mode\n",
        "# opt = tf.keras.optimizers.Adam(learning_rate = 1e-5)\n",
        "\n",
        "## Uncomment this in case you are in TR or FX modes\n",
        "# opt = tf.keras.optimizers.Adam(learning_rate = 1e-3)\n",
        "### ------------------------------------------------- ###\n",
        "\n",
        "model.compile(optimizer= opt, loss='categorical_crossentropy', metrics= 'accuracy')\n",
        "# model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjWv8k_GUKvV"
      },
      "source": [
        "## Fitting the model\n",
        "\n",
        "Here, nothing needs to be changed. The `%%time` function will show the training time at the end of the 40th epoch. However, it may only work in Google Colab (in case you are running this code elsewhere).\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZBv2roCMEfuu"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "N_EPOCHS = 40\n",
        "history = model.fit(train_dataset, epochs = N_EPOCHS, validation_data = validation_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You won't need to run the following block because that was for saving the models which has been already done."
      ],
      "metadata": {
        "id": "Clf6_YU9ur2w"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LNI2-mc6DQqi"
      },
      "outputs": [],
      "source": [
        "## Saving model\n",
        "# save_path = \"/content/drive/MyDrive/Colab Notebooks/SomeFolderOfInterest/\"\n",
        "# model.save(save_path + model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code is for visualizing the accuracy and loss progress during training. It only works when the model is trained in this runtime (and now loaded as a saved model). It plots teh training and validation accuracies and loss."
      ],
      "metadata": {
        "id": "La_GomMLu6EL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mix49bYyzWI0"
      },
      "outputs": [],
      "source": [
        "# Visualize training accuracy and loss\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title(f'model accuracy for {model_name}')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.savefig(f'{save_path}{model_name}-acc.jpg')\n",
        "plt.show()\n",
        "\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title(f'model loss for {model_name}')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.savefig(f'{save_path}{model_name}-loss.jpg')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Computing the Confusion Matrix\n",
        "\n",
        "In order to better understand and visualize the resutls and how the model works, we also adopted ConfusionMatrix from Scikit-learn library and the following code, visualize that.\n",
        "\n",
        "But first, we need to define class_names, and then determine `y_true` using the true labels of the data which is done in the following codeblocks."
      ],
      "metadata": {
        "id": "gorBZ7HQhtSi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eYMBnn4yp-Kc"
      },
      "outputs": [],
      "source": [
        "class_names = test_dataset.class_indices\n",
        "num_classes = len(class_names)\n",
        "class_names = list(class_names.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W1oi4EX7hY2e"
      },
      "outputs": [],
      "source": [
        "def true_label(filepath):\n",
        "  for name in class_names:\n",
        "    if name in filepath:\n",
        "      return name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r_mc5f8uf6Oc"
      },
      "outputs": [],
      "source": [
        "# defining y_true\n",
        "\n",
        "filenames = test_dataset.filenames\n",
        "y_true = np.zeros(len(filenames))\n",
        "\n",
        "for id, filename in enumerate(filenames):\n",
        "  y_true[id] = class_names.index(true_label(filename))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qCQUiKUEfrzx"
      },
      "outputs": [],
      "source": [
        "# compute y_pred\n",
        "preds = model.predict(test_dataset)\n",
        "y_pred = np.argmax(preds,axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xqoK4_y9mpaA"
      },
      "outputs": [],
      "source": [
        "cm = confusion_matrix(y_true=y_true,y_pred=y_pred)\n",
        "\n",
        "# cm_display = ConfusionMatrixDisplay(cm).plot()\n",
        "plt.figure(figsize = (10,8))\n",
        "\n",
        "# Create Confusion Matrix\n",
        "b = sns.heatmap(cm, annot=True,cmap='viridis')\n",
        "\n",
        "# Set the Title\n",
        "b.set(title='Confusion Matrix')\n",
        "\n",
        "# Set the Labels\n",
        "b.set(xlabel='Predicted', ylabel='True')\n",
        "\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "mount_file_id": "11LJ0nyBPQbpSThwGAUWWPbyPKmrV7wHk",
      "authorship_tag": "ABX9TyOjfy23FOB4AqjTItZn+pA/",
      "include_colab_link": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}